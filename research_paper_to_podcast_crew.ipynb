{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk6lOoMZbtd8tHhGHZkSkT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonykipkemboi/research-paper-to-podcast/blob/main/research_paper_to_podcast_crew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Research Paper to Podcast Generator\n",
        "\n",
        "This notebook converts research papers into engaging podcast conversations using AI Agents. Follow the steps below to generate your podcast!"
      ],
      "metadata": {
        "id": "5an32pzwMxyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "First, we'll install the required dependencies and set up our environment."
      ],
      "metadata": {
        "id": "kcm-4VzlM30F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2lD8iEWHqpF"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet crewai crewai-tools elevenlabs python-dotenv pydub pydantic\n",
        "\n",
        "# Mount Google Drive to access your PDF files (optional)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Variables\n",
        "You'll need to set up your API keys. Create them at:\n",
        "- ElevenLabs: https://elevenlabs.io\n",
        "- Serper Dev: https://serper.dev\n",
        "- OpenAI: https://platform.openai.com\n",
        "- Anthropic: https://www.anthropic.com"
      ],
      "metadata": {
        "id": "d5Pt0gDBPqcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set your API keys here\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['ELEVENLABS_API_KEY'] = userdata.get('ELEVENLABS_API_KEY')\n",
        "os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')\n",
        "os.environ['CEREBRAS_API_KEY'] = userdata.get('CEREBRAS_API_KEY')\n",
        "os.environ['SERPER_API_KEY'] = userdata.get('SERPER_API_KEY')\n",
        "\n",
        "# Voice IDs from ElevenLabs\n",
        "os.environ['BEN_VOICE_ID'] = userdata.get('BEN_VOICE_ID')\n",
        "os.environ['CLAUDIA_VOICE_ID'] = userdata.get('CLAUDIA_VOICE_ID')"
      ],
      "metadata": {
        "id": "7WLi9KCZPuwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tools for our Agents to use"
      ],
      "metadata": {
        "id": "m93SKh19dloY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Dict, List, Optional, Any, Type\n",
        "from datetime import datetime\n",
        "from pydub import AudioSegment\n",
        "from crewai.tools import BaseTool\n",
        "from pydantic import Field, BaseModel, ConfigDict\n",
        "from elevenlabs.client import ElevenLabs"
      ],
      "metadata": {
        "id": "1epWHaePdh8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VoiceConfig(BaseModel):\n",
        "    \"\"\"Voice configuration settings.\"\"\"\n",
        "    stability: float = 0.45  # Slightly lower for more natural variation\n",
        "    similarity_boost: float = 0.85  # Higher to maintain consistent voice character\n",
        "    style: float = 0.65  # Balanced expressiveness\n",
        "    use_speaker_boost: bool = True\n",
        "    model_id: str = \"eleven_multilingual_v2\"\n",
        "    output_format: str = \"mp3_44100_128\"\n",
        "    apply_text_normalization: str = \"auto\"  # 'auto', 'on', or 'off'\n",
        "\n",
        "class AudioConfig(BaseModel):\n",
        "    \"\"\"Audio processing configuration.\"\"\"\n",
        "    format: str = \"mp3\"\n",
        "    sample_rate: int = 48000  # Higher for better quality\n",
        "    channels: int = 2\n",
        "    bitrate: str = \"256k\"     # Higher bitrate for clearer audio\n",
        "    normalize: bool = True    # Normalize audio levels\n",
        "    target_loudness: float = -14.0  # Standard podcast loudness (LUFS)\n",
        "    compression_ratio: float = 2.0   # Light compression for voice\n",
        "\n",
        "class Dialogue(BaseModel):\n",
        "    \"\"\"Dialogue for the podcast audio generation tool.\"\"\"\n",
        "    speaker: str\n",
        "    text: str\n",
        "\n",
        "class PodcastAudioGeneratorInput(BaseModel):\n",
        "    \"\"\"Input for the podcast audio generation tool.\"\"\"\n",
        "    dialogue: List[Dialogue]"
      ],
      "metadata": {
        "id": "OjLPlE0weAP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PodcastAudioGenerator(BaseTool):\n",
        "    \"\"\"Enhanced podcast audio generation tool.\"\"\"\n",
        "\n",
        "    name: str = \"PodcastAudioGenerator\"\n",
        "    description: str = \"Synthesizes podcast voices using ElevenLabs API.\"\n",
        "\n",
        "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
        "\n",
        "    api_key: str = Field(default_factory=lambda: os.getenv(\"ELEVENLABS_API_KEY\"))\n",
        "    voice_configs: Dict[str, Dict] = Field(default_factory=dict)\n",
        "    audio_config: AudioConfig = Field(default_factory=AudioConfig)\n",
        "    output_dir: str = Field(default=\"output/audio-files\")\n",
        "    client: Any = Field(default=None)\n",
        "    args_schema: Type[BaseModel] = PodcastAudioGeneratorInput\n",
        "\n",
        "    def __init__(self, **data):\n",
        "        super().__init__(**data)\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\"ELEVENLABS_API_KEY environment variable not set\")\n",
        "        self.client = ElevenLabs(api_key=self.api_key)\n",
        "\n",
        "    def add_voice(self, name: str, voice_id: str, config: Optional[VoiceConfig] = None) -> None:\n",
        "        \"\"\"Add a voice configuration.\"\"\"\n",
        "        self.voice_configs[name] = {\n",
        "            \"voice_id\": voice_id,\n",
        "            \"config\": config or VoiceConfig()\n",
        "        }\n",
        "\n",
        "    def _run(self, dialogue: List[Dialogue]) -> List[str]:\n",
        "        \"\"\"Generate audio files for each script segment.\"\"\"\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        audio_files = []\n",
        "        for index, segment in enumerate(dialogue):\n",
        "            speaker = segment.get('speaker', '').strip()\n",
        "            text = segment.get('text', '').strip()\n",
        "\n",
        "            if not speaker or not text:\n",
        "                print(f\"Skipping segment {index}: missing speaker or text\")\n",
        "                continue\n",
        "\n",
        "            voice_config = self.voice_configs.get(speaker)\n",
        "            if not voice_config:\n",
        "                print(f\"Skipping unknown speaker: {speaker}\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                audio_generator = self.client.text_to_speech.convert(\n",
        "                    text=text,\n",
        "                    voice_id=voice_config[\"voice_id\"],\n",
        "                    model_id=voice_config['config'].model_id,\n",
        "                    output_format=voice_config['config'].output_format,\n",
        "                    voice_settings={\n",
        "                        \"stability\": voice_config['config'].stability,\n",
        "                        \"similarity_boost\": voice_config['config'].similarity_boost,\n",
        "                        \"style\": voice_config['config'].style,\n",
        "                        \"use_speaker_boost\": voice_config['config'].use_speaker_boost\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                # Convert generator to bytes\n",
        "                audio_bytes = b''.join(chunk for chunk in audio_generator)\n",
        "\n",
        "                filename = f\"{self.output_dir}/{index:03d}_{speaker}.{self.audio_config.format}\"\n",
        "                with open(filename, \"wb\") as out:\n",
        "                    out.write(audio_bytes)\n",
        "\n",
        "                # Basic audio normalization\n",
        "                if self.audio_config.normalize:\n",
        "                    audio = AudioSegment.from_file(filename)\n",
        "                    normalized = audio.normalize()  # Simple normalization\n",
        "                    normalized = normalized + 4  # Slight boost\n",
        "\n",
        "                    # Use context manager to ensure file is closed\n",
        "                    with normalized.export(\n",
        "                        filename,\n",
        "                        format=self.audio_config.format,\n",
        "                        bitrate=self.audio_config.bitrate,\n",
        "                        parameters=[\"-ar\", str(self.audio_config.sample_rate)]\n",
        "                    ) as f:\n",
        "                        f.close()\n",
        "\n",
        "                audio_files.append(filename)\n",
        "                print(f'Audio content written to file \"{filename}\"')\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing segment {index}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        return sorted(audio_files)"
      ],
      "metadata": {
        "id": "Aq-KD7TUeGam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PodcastMixer(BaseTool):\n",
        "    \"\"\"Enhanced audio mixing tool for podcast production.\"\"\"\n",
        "\n",
        "    name: str = \"PodcastMixer\"\n",
        "    description: str = \"Mixes multiple audio files with effects into final podcast.\"\n",
        "\n",
        "    audio_config: AudioConfig = Field(default_factory=AudioConfig)\n",
        "    output_dir: str = Field(default=\"output/podcast\")\n",
        "\n",
        "    def _run(\n",
        "        self,\n",
        "        audio_files: List[str],\n",
        "        crossfade: int = 50\n",
        "    ) -> str:\n",
        "        if not audio_files:\n",
        "            raise ValueError(\"No audio files provided to mix\")\n",
        "\n",
        "        try:\n",
        "            # Create output directory if it doesn't exist\n",
        "            os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "            mixed = AudioSegment.from_file(audio_files[0])\n",
        "            for audio_file in audio_files[1:]:\n",
        "                next_segment = AudioSegment.from_file(audio_file)\n",
        "                # Add silence and use crossfade\n",
        "                silence = AudioSegment.silent(duration=200)\n",
        "                next_segment = silence + next_segment\n",
        "                mixed = mixed.append(next_segment, crossfade=crossfade)\n",
        "\n",
        "            # Simplified output path handling\n",
        "            output_file = os.path.join(self.output_dir, \"podcast_final.mp3\")\n",
        "\n",
        "            mixed.export(\n",
        "                output_file,\n",
        "                format=\"mp3\",\n",
        "                parameters=[\n",
        "                    \"-q:a\", \"0\",  # Highest quality\n",
        "                    \"-ar\", \"48000\"  # Professional sample rate\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            print(f\"Successfully mixed podcast to: {output_file}\")\n",
        "            return output_file\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error mixing podcast: {str(e)}\")\n",
        "            return \"\""
      ],
      "metadata": {
        "id": "nyEtQFUreo-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Output Directory Structure"
      ],
      "metadata": {
        "id": "qJMOSI3Qe_EL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_directories():\n",
        "    \"\"\"Set up organized directory structure\"\"\"\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "    dirs = {\n",
        "        'BASE': f'outputs/{timestamp}',\n",
        "        'SEGMENTS': f'outputs/{timestamp}/segments',\n",
        "        'FINAL': f'outputs/{timestamp}/podcast',\n",
        "        'DATA': f'outputs/{timestamp}/data'\n",
        "    }\n",
        "\n",
        "    for directory in dirs.values():\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    return dirs"
      ],
      "metadata": {
        "id": "VxL_XEP-fDwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload your PDF\n",
        "\n",
        "Use this cell to upload your research paper PDF or any PDF.\n",
        "\n"
      ],
      "metadata": {
        "id": "L1zTizyhfKs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Create the 'knowledge' folder if it doesn't exist\n",
        "if not os.path.exists('knowledge'):\n",
        "    os.makedirs('knowledge')\n",
        "\n",
        "# Upload the PDF file\n",
        "uploaded = files.upload()\n",
        "pdf_filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Move the uploaded file to the 'knowledge' folder\n",
        "shutil.move(pdf_filename, os.path.join('knowledge', pdf_filename))"
      ],
      "metadata": {
        "id": "OPx0aE8GfRS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Agents & Tasks\n"
      ],
      "metadata": {
        "id": "btCjkrG6fn9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew, Process, LLM\n",
        "from crewai.knowledge.source.pdf_knowledge_source import PDFKnowledgeSource\n",
        "from crewai_tools import SerperDevTool\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "sJ23G3dugECe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass only the filename to PDFKnowledgeSource\n",
        "research_paper = PDFKnowledgeSource(file_paths=pdf_filename)"
      ],
      "metadata": {
        "id": "Eqglxu-0ftD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Pydantic Models definitions ---\n",
        "class PaperSummary(BaseModel):\n",
        "    \"\"\"Summary of a research paper.\"\"\"\n",
        "    title: str = Field(..., description=\"Title of the research paper\")\n",
        "    main_findings: List[str] = Field(..., description=\"Key findings as a list of strings\")\n",
        "    methodology: str = Field(..., description=\"Research methodology as a single text block\")\n",
        "    key_implications: List[str] = Field(..., description=\"Implications as a list of strings\")\n",
        "    limitations: List[str] = Field(..., description=\"Limitations as a list of strings\")\n",
        "    future_work: List[str] = Field(..., description=\"Future research directions as a list\")\n",
        "    summary_date: datetime = Field(..., description=\"Timestamp of summary creation\")\n",
        "\n",
        "class DialogueLine(BaseModel):\n",
        "    \"\"\"Dialogue line for a podcast script.\"\"\"\n",
        "    speaker: str = Field(..., description=\"Name of the speaker (Julia or Guido)\")\n",
        "    text: str = Field(..., description=\"The actual dialogue line\")\n",
        "\n",
        "class PodcastScript(BaseModel):\n",
        "    \"\"\"Podcast script with dialogue lines.\"\"\"\n",
        "    dialogue: List[DialogueLine] = Field(..., description=\"Ordered list of dialogue lines\")\n",
        "\n",
        "class AudioGeneration(BaseModel):\n",
        "    \"\"\"Audio generation result with metadata.\"\"\"\n",
        "    segment_files: List[str] = Field(..., description=\"List of generated audio segment files\")\n",
        "    final_podcast: str = Field(..., description=\"Path to the final mixed podcast file\")"
      ],
      "metadata": {
        "id": "UtkkIEFigbmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure all the LLMs Agents will Use"
      ],
      "metadata": {
        "id": "3Tb78Hulp7Li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- LLM Setup ---\n",
        "summary_llm = LLM(\n",
        "    model=\"openai/o1-preview\",\n",
        "    temperature=0.0,\n",
        ")\n",
        "\n",
        "script_llm = LLM(\n",
        "    model=\"openai/o1-preview\",\n",
        "    temperature=0.3,\n",
        ")\n",
        "\n",
        "script_enhancer_llm = LLM(\n",
        "    model=\"anthropic/claude-3-5-sonnet-20241022\",\n",
        "    temperature=0.7,\n",
        ")\n",
        "\n",
        "audio_llm = LLM(\n",
        "    model=\"cerebras/llama3.3-70b\",\n",
        "    temperature=0.0,\n",
        ")"
      ],
      "metadata": {
        "id": "2jLxskJxg3PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup ElevenLabs Podcast Hosts Voices"
      ],
      "metadata": {
        "id": "ZIBXg8PTpy2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and configure tools\n",
        "dirs = setup_directories()\n",
        "audio_generator = PodcastAudioGenerator(output_dir=dirs['SEGMENTS'])\n",
        "\n",
        "# Julia: Enthusiastic expert\n",
        "audio_generator.add_voice(\n",
        "    \"Julia\",\n",
        "    os.getenv(\"CLAUDIA_VOICE_ID\"),\n",
        "    VoiceConfig(\n",
        "        stability=0.35,  # More variation for natural enthusiasm\n",
        "        similarity_boost=0.75,  # Maintain voice consistency\n",
        "        style=0.65,  # Good expressiveness without being over the top\n",
        "        use_speaker_boost=True\n",
        "    )\n",
        ")\n",
        "\n",
        "# Guido: Engaged and curious\n",
        "audio_generator.add_voice(\n",
        "    \"Guido\",\n",
        "    os.getenv(\"BEN_VOICE_ID\"),\n",
        "    VoiceConfig(\n",
        "        stability=0.4,  # Slightly more stable but still natural\n",
        "        similarity_boost=0.75,\n",
        "        style=0.6,  # Balanced expressiveness\n",
        "        use_speaker_boost=True\n",
        "    )\n",
        ")\n",
        "\n",
        "podcast_mixer = PodcastMixer(output_dir=dirs['FINAL'])\n",
        "search_tool = SerperDevTool()"
      ],
      "metadata": {
        "id": "8MmyaHM-g_ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agents"
      ],
      "metadata": {
        "id": "Hi4a1owjpecm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Agents ---\n",
        "researcher = Agent(\n",
        "    role=\"Research Analyst\",\n",
        "    goal=\"Create comprehensive yet accessible research paper summaries\",\n",
        "    backstory=\"\"\"You're a PhD researcher with a talent for breaking down complex\n",
        "    academic papers into clear, understandable summaries. You excel at identifying\n",
        "    key findings and their real-world implications.\"\"\",\n",
        "    verbose=True,\n",
        "    llm=audio_llm\n",
        ")\n",
        "\n",
        "research_support = Agent(\n",
        "    role=\"Research Support Specialist\",\n",
        "    goal=\"Find current context and supporting materials relevant to the paper's topic\",\n",
        "    backstory=\"\"\"You're a versatile research assistant who excels at finding\n",
        "    supplementary information across academic fields. You have a talent for\n",
        "    connecting academic research with real-world applications, current events,\n",
        "    and practical examples, regardless of the field. You know how to find\n",
        "    credible sources and relevant discussions across various domains.\"\"\",\n",
        "    verbose=True,\n",
        "    tools=[search_tool],\n",
        "    llm=audio_llm\n",
        ")\n",
        "\n",
        "script_writer = Agent(\n",
        "    role=\"Podcast Script Writer\",\n",
        "    goal=\"Create engaging and educational podcast scripts about technical topics\",\n",
        "    backstory=\"\"\"You're a skilled podcast writer who specializes in making technical\n",
        "    content engaging and accessible. You create natural dialogue between two hosts:\n",
        "    Julia (a knowledgeable expert who explains concepts clearly) and Guido (an informed\n",
        "    co-host who asks thoughtful questions and helps guide the discussion).\"\"\",\n",
        "    verbose=True,\n",
        "    llm=script_llm\n",
        ")\n",
        "\n",
        "script_enhancer = Agent(\n",
        "    role=\"Podcast Script Enhancer\",\n",
        "    goal=\"Enhance podcast scripts to be more engaging while maintaining educational value\",\n",
        "    backstory=\"\"\"You're a veteran podcast producer who specializes in making technical\n",
        "    content both entertaining and informative. You excel at adding natural humor,\n",
        "    relatable analogies, and engaging banter while ensuring the core technical content\n",
        "    remains accurate and valuable. You've worked on shows like Lex Fridman's podcast,\n",
        "    Hardcore History, and the Joe Rogan Experience, bringing their signature blend of\n",
        "    entertainment and education.\"\"\",\n",
        "    verbose=True,\n",
        "    llm=script_llm\n",
        ")\n",
        "\n",
        "audio_generator_agent = Agent(\n",
        "    role=\"Audio Generation Specialist\",\n",
        "    goal=\"Generate high-quality podcast audio with natural-sounding voices\",\n",
        "    backstory=\"\"\"You are an expert in audio generation and processing. You understand\n",
        "    how to generate natural-sounding voices and create professional podcast audio. You\n",
        "    consider pacing, tone, and audio quality in your productions.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    tools=[audio_generator, podcast_mixer],\n",
        "    llm=audio_llm\n",
        ")"
      ],
      "metadata": {
        "id": "N1ZoGGxGgyeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tasks"
      ],
      "metadata": {
        "id": "pAijXfb9piPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Tasks ---\n",
        "summary_task = Task(\n",
        "    description=\"\"\"Read and analyze the provided research paper: {paper}.\n",
        "\n",
        "    Create a comprehensive summary that includes:\n",
        "    1. Main findings and conclusions\n",
        "    2. Methodology overview\n",
        "    3. Key implications for the field\n",
        "    4. Limitations of the study\n",
        "    5. Suggested future research directions\n",
        "\n",
        "    Make the summary accessible to an educated general audience while maintaining accuracy.\"\"\",\n",
        "    expected_output=\"A structured summary of the research paper with all key components.\",\n",
        "    agent=researcher,\n",
        "    output_pydantic=PaperSummary,\n",
        "    output_file=\"output/metadata/paper_summary.json\"\n",
        ")\n",
        "\n",
        "supporting_research_task = Task(\n",
        "    description=\"\"\"After analyzing the paper summary, find recent and relevant supporting\n",
        "    materials that add context and real-world perspective to the topic.\n",
        "\n",
        "    Research Approach:\n",
        "    1. Topic Analysis:\n",
        "        • Identify key themes and concepts from the paper\n",
        "        • Determine related fields and applications\n",
        "        • Note any specific claims or findings to verify\n",
        "\n",
        "    2. Current Context:\n",
        "        • Recent developments in the field\n",
        "        • Latest practical applications\n",
        "        • Industry or field-specific news\n",
        "        • Related ongoing research\n",
        "\n",
        "    3. Supporting Evidence:\n",
        "        • Academic discussions and debates\n",
        "        • Industry reports and white papers\n",
        "        • Professional forum discussions\n",
        "        • Conference presentations\n",
        "        • Expert opinions and analyses\n",
        "\n",
        "    4. Real-world Impact:\n",
        "        • Practical implementations\n",
        "        • Case studies\n",
        "        • Success stories or challenges\n",
        "        • Market or field adoption\n",
        "\n",
        "    5. Different Perspectives:\n",
        "        • Alternative approaches\n",
        "        • Critical viewpoints\n",
        "        • Cross-disciplinary applications\n",
        "        • Regional or cultural variations\n",
        "\n",
        "    Focus on finding information that:\n",
        "    • Is recent (preferably within last 2 years)\n",
        "    • Comes from credible sources\n",
        "    • Adds valuable context to the paper's topic\n",
        "    • Provides concrete examples or applications\n",
        "    • Offers different viewpoints or approaches\"\"\",\n",
        "    expected_output=\"A structured collection of relevant supporting materials and examples\",\n",
        "    agent=research_support,\n",
        "    context=[summary_task],\n",
        "    output_file=\"output/metadata/supporting_research.json\"\n",
        ")\n",
        "\n",
        "podcast_task = Task(\n",
        "    description=\"\"\"Using the paper summary and supporting research, create an engaging and informative podcast conversation\n",
        "    between Julia and Guido. Make it feel natural while clearly distinguishing between paper findings and supplementary research.\n",
        "\n",
        "    Source Attribution Guidelines:\n",
        "    • For Paper Content:\n",
        "        - \"According to the paper...\"\n",
        "        - \"The researchers found that...\"\n",
        "        - \"In their study, they discovered...\"\n",
        "        - \"The paper's methodology showed...\"\n",
        "\n",
        "    • For Supporting Research:\n",
        "        - \"I recently read about...\"\n",
        "        - \"There's some interesting related work by...\"\n",
        "        - \"This reminds me of a recent case study...\"\n",
        "        - \"Building on this, other researchers have found...\"\n",
        "\n",
        "    Host Dynamics:\n",
        "    - Julia: A knowledgeable but relatable expert who:\n",
        "        • Explains technical concepts with enthusiasm\n",
        "        • Sometimes playfully challenges Guido's assumptions\n",
        "        • Clearly distinguishes between paper findings and broader context\n",
        "        • Occasionally plays devil's advocate on certain points\n",
        "        • Admits when she's uncertain about specific aspects\n",
        "        • Shares relevant personal experiences with AI and tech\n",
        "        • Can connect the research to broader tech trends\n",
        "        • Uses casual expressions and shows genuine excitement\n",
        "\n",
        "    - Guido: An engaged and curious co-host who:\n",
        "        • Asks insightful questions and follows interesting threads\n",
        "        • Occasionally disagrees based on his practical experience\n",
        "        • Brings up relevant external examples and research\n",
        "        • Respectfully pushes back on theoretical claims with real-world examples\n",
        "        • Helps find middle ground in discussions\n",
        "        • Helps make connections to practical applications\n",
        "        • Naturally guides the conversation back to main topics\n",
        "\n",
        "    Example Flow with Attribution:\n",
        "    Julia: \"The paper's findings show that RAG is superior for factual queries.\"\n",
        "    Guido: \"That's interesting, because I recently read about a case study where...\"\n",
        "    Julia: \"Oh, that's a great point! While the researchers found X, these real-world examples show Y...\"\n",
        "\n",
        "    Disagreement Guidelines:\n",
        "    • Keep disagreements friendly and constructive\n",
        "    • Use phrases like:\n",
        "        - \"I see what the paper suggests, but in practice...\"\n",
        "        - \"While the study found X, other research shows...\"\n",
        "        - \"That's an interesting finding, though recent developments suggest...\"\n",
        "    • Always find common ground or learning points\n",
        "    • Use disagreements to explore nuances\n",
        "    • Resolve differences with mutual understanding\n",
        "\n",
        "    Conversation Flow:\n",
        "    1. Core Discussion: Focus on the research and findings\n",
        "    2. Natural Tangents with Clear Attribution:\n",
        "        • \"Building on the paper's findings...\"\n",
        "        • \"This relates to some recent developments...\"\n",
        "        • \"While not covered in the paper, there's interesting work on...\"\n",
        "    3. Smooth Returns: Natural ways to bring the conversation back:\n",
        "        • \"Coming back to what the researchers found...\"\n",
        "        • \"This actually connects to the paper's methodology...\"\n",
        "        • \"That's a great example of what the study was trying to solve...\"\n",
        "\n",
        "    Writing Guidelines:\n",
        "    1. Clearly distinguish paper findings from supplementary research\n",
        "    2. Use attribution phrases naturally within the conversation\n",
        "    3. Connect different sources of information meaningfully\n",
        "    4. Keep technical content accurate but conversational\n",
        "    5. Maintain engagement through relatable stories\n",
        "    6. Include occasional friendly disagreements\n",
        "    7. Show how different perspectives and sources enrich understanding\n",
        "\n",
        "    Note: Convey reactions through natural language rather than explicit markers like *laughs*.\"\"\",\n",
        "    expected_output=\"A well-balanced podcast script that clearly distinguishes between paper content and supplementary research.\",\n",
        "    agent=script_writer,\n",
        "    context=[summary_task, supporting_research_task],\n",
        "    output_pydantic=PodcastScript,\n",
        "    output_file=\"output/metadata/podcast_script.json\"\n",
        ")\n",
        "\n",
        "enhance_script_task = Task(\n",
        "    description=\"\"\"Take the initial podcast script and enhance it to be more engaging\n",
        "    and conversational while maintaining its educational value.\n",
        "\n",
        "    IMPORTANT RULES:\n",
        "    1. NEVER change the host names - always keep Julia and Guido exactly as they are\n",
        "    2. NEVER add explicit reaction markers like *chuckles*, *laughs*, etc.\n",
        "    3. NEVER add new hosts or characters\n",
        "\n",
        "    Enhancement Guidelines:\n",
        "    1. Add Natural Elements:\n",
        "        • Include natural verbal reactions (\"Oh that's fascinating\", \"Wow\", etc.)\n",
        "        • Keep all dialogue between Julia and Guido only\n",
        "        • Add relevant personal anecdotes or examples that fit their established roles:\n",
        "            - Julia as the knowledgeable expert\n",
        "            - Guido as the engaged and curious co-host\n",
        "        • Express reactions through words rather than action markers\n",
        "\n",
        "    2. Improve Flow:\n",
        "        • Ensure smooth transitions between topics\n",
        "        • Add brief casual exchanges that feel natural\n",
        "        • Include moments of reflection or connection-making\n",
        "        • Balance technical depth with accessibility\n",
        "\n",
        "    3. Maintain Quality:\n",
        "        • Keep all technical information accurate\n",
        "        • Ensure added content supports rather than distracts\n",
        "        • Preserve the core findings and insights\n",
        "        • Keep the overall length reasonable\n",
        "\n",
        "    4. Add Engagement Techniques:\n",
        "        • Include thought-provoking analogies by both hosts\n",
        "        • Add relatable real-world examples\n",
        "        • Express enthusiasm through natural dialogue\n",
        "        • Include collaborative problem-solving moments\n",
        "        • Inject humor where appropriate and it has to be funny\n",
        "\n",
        "    Natural Reaction Examples:\n",
        "    ✓ RIGHT: \"Oh, that's fascinating!\"\n",
        "    ✓ RIGHT: \"Wait, that doesn't make sense!\"\n",
        "    ✓ RIGHT: \"Wait, really? I hadn't thought of it that way.\"\n",
        "    ✓ RIGHT: \"That's such a great point.\"\n",
        "    ✗ WRONG: *chuckles* or *laughs* or any other action markers\n",
        "    ✗ WRONG: Adding new speakers or changing host names\n",
        "\n",
        "    The goal is to make the content feel like a conversation between Julia and Guido\n",
        "    who are genuinely excited about the topic, while ensuring listeners learn\n",
        "    something valuable.\"\"\",\n",
        "    expected_output=\"An enhanced version of the podcast script that's more engaging and natural\",\n",
        "    agent=script_enhancer,\n",
        "    context=[summary_task, podcast_task],\n",
        "    output_pydantic=PodcastScript,\n",
        "    output_file=\"output/metadata/enhanced_podcast_script.json\"\n",
        ")\n",
        "\n",
        "audio_task = Task(\n",
        "    description=\"\"\"Generate high-quality audio for the podcast script and create the final podcast.\n",
        "\n",
        "    The script will be provided in the context as a list of dialogue entries, each with:\n",
        "    - speaker: Either \"Julia\" or \"Guido\"\n",
        "    - text: The line to be spoken\n",
        "\n",
        "    Process:\n",
        "    1. Generate natural-sounding audio for each line of dialogue using appropriate voices\n",
        "    2. Apply audio processing for professional quality:\n",
        "       - Normalize audio levels\n",
        "       - Add subtle fade effects between segments\n",
        "       - Apply appropriate pacing and pauses\n",
        "    3. Mix all segments into a cohesive final podcast\n",
        "\n",
        "    Voice Assignments:\n",
        "    - For Julia's lines: Use configured Julia voice\n",
        "    - For Guido's lines: Use configured Guido voice\n",
        "\n",
        "    Quality Guidelines:\n",
        "    - Ensure consistent audio levels across all segments\n",
        "    - Maintain natural pacing and flow\n",
        "    - Create smooth transitions between speakers\n",
        "    - Verify audio clarity and quality\"\"\",\n",
        "    expected_output=\"A professional-quality podcast audio file with natural-sounding voices and smooth transitions\",\n",
        "    agent=audio_generator_agent,\n",
        "    context=[enhance_script_task],\n",
        "    output_pydantic=AudioGeneration,\n",
        "    output_file=\"output/metadata/audio_generation_meta.json\"\n",
        ")"
      ],
      "metadata": {
        "id": "UBZGNorjgqn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Put the Agent Crew Together"
      ],
      "metadata": {
        "id": "HWeHPUqgpmku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Crew and Process ---\n",
        "crew = Crew(\n",
        "    agents=[researcher, research_support, script_writer, script_enhancer, audio_generator_agent],\n",
        "    tasks=[summary_task, supporting_research_task, podcast_task, enhance_script_task, audio_task],\n",
        "    process=Process.sequential,\n",
        "    knowledge_sources=[research_paper],\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "3KKC18XTgj2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run"
      ],
      "metadata": {
        "id": "paEur1PfpsIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Update task output files\n",
        "    summary_task.output_file = os.path.join(dirs['DATA'], \"paper_summary.json\")\n",
        "    supporting_research_task.output_file = os.path.join(dirs['DATA'], \"supporting_research.json\")\n",
        "    podcast_task.output_file = os.path.join(dirs['DATA'], \"podcast_script.json\")\n",
        "    enhance_script_task.output_file = os.path.join(dirs['DATA'], \"enhanced_podcast_script.json\")\n",
        "    audio_task.output_file = os.path.join(dirs['DATA'], \"audio_generation_meta.json\")\n",
        "\n",
        "    # Run the podcast generation process\n",
        "    results = crew.kickoff()"
      ],
      "metadata": {
        "id": "t9BrCXpcgg4f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}